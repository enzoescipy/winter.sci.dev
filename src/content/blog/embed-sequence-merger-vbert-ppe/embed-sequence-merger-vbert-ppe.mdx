---
author: WINTER.SCI.DEV
pubDatetime: 2025-10-25T22:05:00.000+09:00
title: "vBERT: 임베딩을 다시 임베딩하기? 처음으로 인공지능을 손수 만들어본 소감"
slug: embed-sequence-merger-vbert-ppe
featured: true
draft: false
tags:
  - AI
  - NLP
  - vBERT
  - PPE
  - Embed Sequence Merger
  - FINESSE
  - 커피과학
  - CVA
  - 센서리과학
description: "BERT가 단어를 이해한다면, vBERT는 맥락의 흐름을 '기억'한다. 긴 임베딩 시퀀스를 합성하며 의미를 보존하는 혁명적 벡터. 특수 커피 평가의 복잡한 패턴 추출처럼, vBERT가 RAG 시스템과 과학적 발견을 어떻게 재정의할까"
---

import { Image } from 'astro:assets';
import LinkButton from '@components/LinkButton.astro';
import CaptionCenteredImage from '@components/CaptionCenteredImage.astro';
import { LinkPreview } from 'astro-embed';

import coffeeAndTimeImage from "./source/coffee-and-time.jpg";
import robotReadingImage from "./source/robot-reading.jpg";
import filmMovieImage from "./source/film-movie.jpg";
import dataFlowImage from "./source/data-flow.jpg";
import debateImage from "./source/debate.jpg";
import colaborateImage from "./source/colaborate.jpg";
import writeImage from "./source/write.jpg";



<CaptionCenteredImage 
  imageSrc={coffeeAndTimeImage}
  caption="커피와 함께 흘러가는 시간."
  imageAlt="커피와 함께 흘러가는 시간."
/>


### 긴 대화를 나누다 보면, 제일 처음에 나눴던 이야기의 맛이 희미해지곤 합니다. 

예를 들어, 커피 한 잔을 마시며 친구와 나눴던 깊은 수다—처음의 신맛과 단맛이 어우러진 그 특별한 향이, **시간이 지나면서 '그냥 맛있는 커피'로 추상화되죠.** 우리는 기억의 흐름 속에서 맥락을 잃지 않기 위해 끊임없이 되뇌이지만, 때론 하나의 연결 고리가 끊어지면서 전체가 흐트러지죠. ~~분명히 태종태세문단세 다음에 뭔가 있었는데... 까먹었네요.~~

하지만 조화로운 커피의 미세한 맛의 기억이, 과연 뭉게지고 희미해지기만 할까요? 

**절대 그렇지 않습니다.**

저는 인간에게는 AI에겐 없는 특별한 힘이 있다고 생각합니다. 그것은 바로, **아름답게 잊는 능력**입니다. 

사람은 잊습니다. 하지만, 그와 동시에 기억을 압축하고, 희미하게 연결해둡니다. 미묘한 커피의 향미에 대한 인상은 사라지지만, 무심코 맡은 비슷한 향기에 우리는 그때 커피를 즐기며 만났던 오래 전 옛 친구에 대해서 떠올립니다. **이것이 바로 인간의 기억이 가진 유연성입니다.**

## ChatGPT 에게는 기억이 없다 : Transformer 디코더 아키텍처

<CaptionCenteredImage 
  imageSrc={robotReadingImage}
  caption="기계학습은 AI의 모든것이지만, 아이러니하게도 AI는 배우는게 태생적으로 불가능한 존재입니다."
  imageAlt="기계학습은 AI의 모든것이지만, 아이러니하게도 AI는 배우는게 태생적으로 불가능한 존재입니다."
/>

**언제부턴가, AI가 똑똑해지기 시작했지 않나요?** 

모든 시발점은 Google이 발표한 단 하나의 논문이었습니다. 

<blockquote>
[Attention Is All You Need](https://arxiv.org/abs/1706.03762) — 말 그대로 *"프로그램에게 주의집중 만 시키면 AI가 될 것이다"*
</blockquote>

이 어찌보면 폭력적인 주장은, 이후 전 세계를 LLM 광풍으로 몰아넣었습니다.<sup><a id='cite-ref-1' href='#cite-fn-1' className='inline-link'>1</a></sup><sup><a id='cite-ref-2' href='#cite-fn-2' className='inline-link'>2</a></sup> ChatGPT, Gemini, Sonnet 등 다양한 생성형 AI들이, 이 논문에서 나왔습니다. 

그 원리는 절대 단순하진 않습니다. 하지만, 쉽게 말해보자면 그들은 *"누가누가 더 자연스럽게 글 덧붙이기 잘하나"* 놀이를 시켰다고 볼 수 있겠네요. ~~(?)~~

<CaptionCenteredImage 
  imageSrc={writeImage}
  caption="릴레이 이야기 쓰기, 해보신 적 있으신가요?"
  imageAlt="릴레이 이야기 쓰기, 해보신 적 있으신가요?"
/>

*"옛날 옛적에..."* → *"...작은 마을에..."* → *"...한 소년이 살았습니다."*

그런데 중간에 어떤 사람이 갑자기 **"그런데 사실 주인공은 요정이었다!"** 라고 중간에 뜬금없이 새 규칙을 만들면 어떻게 될까요?

그 뒤의 사람들은 당황하겠지만, 어쩔 수 없이 그 규칙을 따라야 합니다. 그리고 또 그 규칙에 맞게 **"요정이었던 주인공은 요정의 세계로 돌아갈 수밖에 없었어요."** 하고 안정을 찾아가는 그 느낌.

**왠지 ChatGPT와 우리의 대화 같지 않나요?**

이 과정을 "어텐션(Attention)"이라고 합니다. 각 단어가 서로를 바라보고(Attention!), "너는 내게 이렇게 중요한 거구나" 라는 관계의 강도를 계산하는 거죠.

이것이 바로 논문의 절반이자 전세계를 사로잡고 있는 LLM의 근간 원리, **"Transformer 디코더"** 입니다. 

<blockquote>
그들은 단순한 **"말 덧붙이기 기계"** 입니다.
</blockquote>

하지만, 그 **"뒷말"** 의 길이가 백과사전 수십개 분량이기 때문에 마치 기억을 가진 것처럼 행동하는 것이 가능한 것입니다. 그런데, 그럼 이런 의문이 듭니다.

<blockquote>
  *"뒷말"* 의 길이에는 한계가 있는가? 있다면, 그 한계를 넘은 문장은 어디로 가는가?
</blockquote>

정답은 명확합니다.

**사라집니다. 완전히.**

## 이야기에는 끝이 있는 법

다시 릴레이 이야기 만들기를 생각해봅시다. 만들던 이야기가 너무 길어져서 *"아, 처음에 뭐라고 썼더라?"* 하고 맨 앞 장을 다시 보려고 해도, 이미 그 페이지는 다른 사람의 손에 넘어가 버리지 않나요? **처음의 그 결정적인 문장은, 더 이상 현재의 이야기 흐름에 영향을 주지 못하는 겁니다.**

이것이 바로 Transformer의 가장 큰 한계, **"컨텍스트 윈도우(Context Window)"** 입니다. AI는 이 윈도우 안에 들어오는 단어들만 서로의 관계를 파악할 수 있습니다. 윈도우를 벗어난 단어는, 마치 책의 첫 페이지를 찢어버린 것처럼, 존재 자체가 무시됩니다. 

**그들은 *"뒷말"* 안의 모든 것을 기억하지만, 그 바깥의 어떤 것도 기억하지 못합니다.**

<CaptionCenteredImage 
  imageSrc={dataFlowImage}
  caption="큰 힘에는 큰 대가가 따르죠."
  imageAlt="큰 힘에는 큰 대가가 따르죠."
/>

Transformer 아키텍처의 *"주의집중(Attention)"* 은 아름답지만, 엄청난 비용이 듭니다. **단어가 10개면 10x10=100번의 계산을, 100개면 100x100=10,000번의 계산을 해야 합니다.** 그래서 실용적인 이유로, 이 계산 범위를 일정 길이로 제한합니다. 아니, 의도적으로 그 제한된 길이 이상을 처리하지 못하도록 학습시킵니다. 이것이, 오늘날 모든 LLM들이 가진 공통적인 특징입니다.

<blockquote>
  ***네게 모든 보는 것을 이해하는 권능을 주마. 하지만 내일이 되면, 네가 무엇을 봤는지 조차 잊어먹게 될 것이다.***
</blockquote>

## 그럼, 과연 AI는 영원히 망각의 노예일 수밖에 없을까?

우리가 지금까지 살펴본 '릴레이 이야기 쓰기' 방식은, 사실 *"Attention Is All You Need"* 논문이 제안한 **절반의 해법**이었습니다. 이 논문은 두 가지의 근본적으로 다른 아키텍처를 제시했는데, 하나는 우리가 봤던 **디코더(Decoder)**, 그리고 나머지 하나는 바로 **인코더(Encoder)** 입니다.

<blockquote>
**디코더는 "무엇을 쓸지"를 고민하는 작가라면, 인코더는 "무엇이 쓰였는지"를 분석하는 평론가입니다.**
</blockquote>

이 두 가지는 같은 뿌리(Attention)에서 나왔지만, 그 목적과 방식이 완전히 다릅니다. 디코더가 '릴레이 이야기 쓰기'였다면, 인코더는 **'격렬한 독서 토론회'**에 비유할 수 있습니다.

### BERT, 잊혀진 형제 : 격렬한 독서 토론회

<CaptionCenteredImage 
  imageSrc={debateImage}
  caption="열띤 토론이 빚는 새로운 의미의 탄생, 그것이 BERT의 철학입니다."
  imageAlt="열띤 토론이 빚는 새로운 의미의 탄생, 그것이 BERT의 철학입니다."
/>


독서 토론회를 상상해보세요. 참가자들은 모두 같은 책을 읽습니다. 그리고 토론이 시작되면, 누구나 책의 어떤 부분이든 자유롭게 인용하며 그 의미를 파고듭니다.

*   "3장에서 주인공이 한 그 말, 사실 1장의 첫 대사와 연결되는 거 아니야?"
*   "결말이 충격적인데, 5장 중반에 나왔던 그 작은 단서가 복선이었구나!"

**인코더는 바로 이 '독서 토론회'의 원리를 그대로 구현합니다.** 디코더가 한 방향으로만(과거→미래) 이야기를 썼다면, 인코더는 문장의 **처음, 중간, 끝을 동시에 보면서 모든 단어의 '진짜 의미'를 파악**합니다. 이것이 바로 BERT의 'B'가 의미하는 **'양방향(Bidirectional)'**의 힘입니다.

<blockquote>
**인코더는 문장 전체를 한 번에 훑어, 각 단어가 다른 모든 단어와 맺는 관계를 총체적으로 이해합니다.**
</blockquote>

### 재잘재잘 GPT와 묵언수행 BERT 

그 결과, 인코더 BERT는 '다음 단어'를 예측하지 않습니다. 대신, 문장 전체의 의미를 깊이 있게 응축한, 정제된 **'이해의 정수(Essence of Understanding)'** 숫자 뭉치를 뱉어냅니다.<sup><a id='cite-ref-3' href='#cite-fn-3' className='inline-link'>3</a></sup>

이것은 단순한 수의 나열이 아닙니다. 문장의 감정, 뉘앙스, 숨겨진 의미까지 모두 포함한, 그 문장에 대한 **깊은 통찰**입니다. 인코더는 문장을 '이해'하고, 그 이해를 숫자로 표현하는 전문가인 셈입니다.

실제로 이렇게 나온 숫자 뭉치를 - 개발자들은 ***임베딩 벡터*** 라고 부릅니다 - 조금 더 깊이 살펴보면, 정말 신기한 일들이 일어납니다. 서로 비슷한 문장을 BERT가 빚어 만든 숫자뭉치가 서로 비슷할까요? 그건 당연합니다. 

심지어는 이런 짓도 할 수 있습니다. 가령, 
- "나는 밥을 먹는다."
- "아까 회의 재밌었는데."
- "깊은 산속 옹달샘 누가와서 먹나요?"
- "화성 탐사를 가는 것은 너무 미래지향적입니다."

를 모두 숫자 뭉치로 바꿔서 - 개발자들은 ***임베딩을 한다*** 라고 합니다 - **"지구에 도움이 되는 아이디어는 무엇일까?"** 라는 질문을 숫자 뭉치로 바꾸고, 아까 만들어둔 4개의 숫자 뭉치와 서로 가까운 순위를 매겨보면? 놀랍게도 **"화성 탐사를 가는 것은 너무 미래지향적입니다."** 가 나오게 됩니다. 

<blockquote>
  **ChatGPT와 다르게, BERT 는 말을 할 수 없었습니다. 그래서 그들은 숫자로 자신의 의사를 표현한 것입니다.**
</blockquote>


## BERT 와 GPT 의 만남

<CaptionCenteredImage 
  imageSrc={colaborateImage}
  caption="서로 다른 두 AI가 협력하는 시스템을 상상하는 일은, 아주 자연스러웠죠."
  imageAlt="서로 다른 두 AI가 협력하는 시스템을 상상하는 일은, 아주 자연스러웠죠."
/>


<blockquote>
  **"하지만 BERT는 말을 할 수 없었습니다."**
</blockquote>

우리는 지금까지 두 명의 천재를 만났습니다. 한 명은 유창한 **작가(GPT)**, 다른 한 명은 침묵하는 **사서(BERT)** 였죠. **작가**는 누구보다 멋진 글을 쓸 수 있었지만, 기억력이 형편없었습니다. 반면, **사서**는 방대한 지식의 바다를 꿰뚫고 있었지만, 자신의 생각을 말로 표현할 수 없었습니다.

<blockquote>
  **"그렇다면, 이 둘을 합친다면 어떨까요?"**
</blockquote>

이 질문이 바로 **검색 증강 생성(Retrieval-Augmented Generation)**, 줄여서 **RAG**라는 기술의 시작점이었습니다.<sup><a id='cite-ref-4' href='#cite-fn-4' className='inline-link'>4</a></sup> 이는 마치 **오픈북 시험**을 보는 것과 같습니다.

### 오픈북 시험, RAG

1.  **질문:** 사용자가 **GPT**에게 "특수 커피의 산미와 단맛의 균형을 설명해줘"라고 질문합니다.
2.  **검색 의뢰:** **GPT**는 대답하기 전에, **BERT**에게 질문의 **핵심 키워드**(예: "특수 커피", "산미", "단맛", "균형")를 알려줍니다.
3.  **지식 조달:** **BERT**는 자신이 관리하는 거대한 숫자 뭉치의 도서관을 뒤져서, 키워드들과 가장 의미가 가까운, **가장 관련성 높은 정보가 담긴 단 하나의 책**을 찾아 **GPT**에게 건네줍니다.
4.  **생성:** **GPT**는 그 페이지를 참고 자료로 삼아, 마치 원래부터 그 답을 알고 있었던 것처럼 유창하게 대답을 작성합니다.

<blockquote>
  **"RAG는 결국, 말 못하는 천재 사서(**BERT**)의 지혜를, 유창한 작가(**GPT**)의 입을 빌려 세상에 전하는 기술입니다."**
</blockquote>

이것은 AI 역사상 가장 현명한 해결책 중 하나였습니다. 기억력이 없는 AI에게, 필요할 때마다 정확한 참고서를 찾아주는 개인 사서를 붙여준 셈이니까요.


## 긴 글이 지났습니다. 저와 여러분과의 첫인상은, 이제 어떻게 변했나요?

<CaptionCenteredImage 
  imageSrc={coffeeAndTimeImage}
  caption="이 사진을 다시 보셨을 때 떠오르는 감정은 이제 무엇인가요?"
  imageAlt="이 사진을 다시 보셨을 때 떠오르는 감정은 이제 무엇인가요?"
  className='h-[500px] object-cover'
/>

어느날 저녁, 나지막하니 의자에 기대 밤커피를 마십니다. 씁쓸한 맛과 함께, 어딘지 모를 쓸쓸한 향기도 같이 피어오릅니다. 철야 작업을 할 때면, 이런 기분이 들더라고요. 이 쓸쓸한 감정과 씁쓸한 커피는, 사실 전혀 관계가 없는 의미를 가지고 있습니다. 하지만 제 마음속에서는, 습관적인 행위를 통해 어느덧 같은 배를 탄, 하나의 의미 덩어리를 구성하게 되었네요.

이제 꽤나 대화 기록이 많이 쌓인 ChatGPT에게, 커피에 대해서 다시 물어봤습니다. **나 지금 커피 마시고 있어.**

- *ChatGPT는, 이전까지의 대화 기록을 BERT 를 통해 색인하는 RAG를 수행.*
- *커피와 의미적으로 연관이 깊은 모든 기록을 복기.*
- *이전에 마신 커피란 커피는 전부 끌어모읍니다.*

그리곤 대답합니다. **이전에 마셨던 에티오피아, 케냐, 브라질 커피 중 어떤 커피와 맛이 비슷하신가요? 너무 궁금합니다.**

그때, 사랑하는 어머니가 방문을 열고 들어옵니다.

<blockquote>
  **오늘은 컴퓨터 좀 그만 하렴. 왠 밤에 커피니. 몸상할라.**
</blockquote>

## vBERT, 시간의 연금술사: 의미의 감옥을 넘어 시간을 이해하다

ChatGPT는 아주 예의 바르고 훌륭하게 대답했습니다. RAG라는 '의미의 도서관'을 참조했기에, 커피와 관련된 과거의 모든 대화 기록을 완벽하게 '의미적으로' 연결하여 복기해냈습니다. 하지만 밤과 커피, 그리고 고독과 가족의 걱정이라는, 우리에게는 너무나도 중요했던 **'시간적 맥락'** 을 전혀 이해하지 못했습니다.

RAG에게 어머니의 이야기는 그저 '또 다른 텍스트 단편'일 뿐입니다. 매일 밤 저를 걱정하시는 어머니의 마음과 밤에 마시는 커피의 연관성이 또 하나의 거대한 '사건'임을 그녀는 알지 못합니다.

<blockquote>
  **"만약 AI에게, 서로 다른 두 권의 책(커피와 어머니의 이야기)을 시간 순서대로 보여주고, 그 '시간의 흐름' 속에서 무슨 일이 일어났는지 단 하나의 벡터로 요약하라고 시키면 어떨까?"**
</blockquote>

이것이 바로 **vBERT**(Vectorized BERT)의 핵심 질문이었습니다. vBERT는 단어(Text)의 배열을 학습하는 BERT와 달리, **의미 덩어리(Vector)의 배열, 즉 Sequence of Embeddings** 자체를 학습하기 위해 태어났습니다.

<CaptionCenteredImage 
  imageSrc={filmMovieImage}
  caption="의미의 흐름을 마치 한 편의 영화처럼 읽어내는 AI"
  imageAlt=""
  className='h-[500px] object-cover'
/>

vBERT는 시간의 흐름 속에 놓인 '씁쓸한 커피' `벡터`, '쓸쓸한 감정' `벡터`, 그리고 '어머니의 걱정' `벡터`를 각각 독립적으로 보는 것이 아닙니다. vBERT는 이 세 가지 분리된 의미 덩어리(벡터)들을 하나의 '시간적 흐름' 안에서 녹여내, 최종적으로 **'그날 밤의 분위기'** 라는, 단 하나의 새로운 `벡터`로 응축해냅니다.

마치 한 편의 영화에서 각 장면의 의미(벡터)들이 합쳐져 영화 전체의 핵심 감정(하나의 새로운 벡터)을 만들어내듯이, vBERT는 시간적으로 이어진 여러 임베딩 시퀀스를 하나의 최종적인 '시퀀스 임베딩'으로 제련하는 **'시간의 연금술사'** 입니다.

<blockquote>
  **"vBERT는 AI가 마침내 '의미'의 감옥을 부수고, '시간'을 이해하도록 돕는 새로운 시대의 서막을 열었습니다."**
</blockquote>

이제 AI는 단순히 '무슨 단어가 다음으로 올지' 혹은 '어떤 문서가 가장 관련 있을지'를 넘어, '어떤 사건들이 어떤 순서로 일어나 전체 이야기의 맥락을 형성하는지'를 파악할 수 있게 된 것입니다.

이것이 바로, 제가 여러분에게 소개하고자 하는 **vBERT** 입니다. 

*(문서는 계속하여 최신화됩니다. 곧 관심있는 분들께 제 vBERT 기술로 빚어낸 모델을, 자신있게 이곳에서 선보이겠습니다. 감사합니다.)*

*(다만, 혹시 기술적 디테일에 관심이 있으신 분은, [제가 혼신을 다해 올린 영문 아티클](https://www.winter-sci-dev.com/posts/embed-sequence-merger-vbert-ppe-article/) 을 보시면 좋을 것 같습니다.)*

감사합니다.

<details>
  <summary>참고자료 | Reference And Citation</summary>
  <p>
    <a href="#cite-ref-1" id="cite-fn-1" className='inline-link'>[1]</a>
    <a href="https://health.chosun.com/news/dailynews_view.jsp?mn_idx=426342&utm_source=chatgpt.com" className='inline-link'>챗GPT, 너의 능력은 어디까지?</a>, 헬스조선
  </p>
  <p>
    <a href="#cite-ref-2" id="cite-fn-2" className='inline-link'>[2]</a>
    <a href="https://time.com/6238781/chatbot-chatgpt-ai-interview/?utm_source=chatgpt.com" className='inline-link'>AI Chatbots Are Getting Better. But an Interview With ChatGPT Reveals Their Limits</a>, Times
  </p>
  <p>
    <a href="#cite-ref-3" id="cite-fn-3" className='inline-link'>[3]</a>
    <a href="https://arxiv.org/abs/1810.04805" className='inline-link'>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>, Jacob Devlin et al.
  </p>
  <p>
    <a href="#cite-ref-4" id="cite-fn-4" className='inline-link'>[4]</a>
    <a href="https://arxiv.org/abs/2005.11401" className='inline-link'>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a>, Patrick Lewis et al.
  </p>
</details>